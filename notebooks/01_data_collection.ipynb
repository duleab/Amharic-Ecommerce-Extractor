{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Amharic E-commerce Data Collection\n",
        "\n",
        "This notebook demonstrates how to collect Amharic e-commerce data from Telegram channels for Named Entity Recognition (NER) tasks.\n",
        "\n",
        "## Overview\n",
        "\n",
        "In this notebook, we will:\n",
        "\n",
        "1. Set up the Telegram API client\n",
        "2. Connect to Ethiopian e-commerce Telegram channels\n",
        "3. Scrape messages containing product information\n",
        "4. Save the collected data for further processing\n",
        "\n",
        "## Requirements\n",
        "\n",
        "Before running this notebook, make sure you have:\n",
        "\n",
        "1. Telegram API credentials (API ID and API Hash)\n",
        "2. A registered Telegram phone number\n",
        "3. The required Python packages installed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pandas'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatetime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m datetime\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtqdm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnotebook\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Add the project root directory to the Python path\u001b[39;00m\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import asyncio\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "# Add the project root directory to the Python path\n",
        "project_root = Path().resolve().parent\n",
        "if str(project_root) not in sys.path:\n",
        "    sys.path.append(str(project_root))\n",
        "\n",
        "# Import the TelegramScraper class from our custom module\n",
        "from src.data.telegram_scraper import TelegramScraper\n",
        "\n",
        "# Note: We'll set environment variables directly in the notebook\n",
        "# instead of using dotenv for simplicity\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set up Telegram API credentials\n",
        "# Replace these with your actual credentials\n",
        "API_ID = \"YOUR_API_ID\"  # Get from https://my.telegram.org/apps\n",
        "API_HASH = \"YOUR_API_HASH\"  # Get from https://my.telegram.org/apps\n",
        "PHONE = \"+1234567890\"  # Your phone number with country code\n",
        "\n",
        "# List of Ethiopian e-commerce Telegram channels to scrape\n",
        "CHANNELS = [\n",
        "    \"@shageronlinestore\",  # Example channel\n",
        "    # Add more channels here\n",
        "]\n",
        "\n",
        "# Output directory for saving scraped data\n",
        "OUTPUT_DIR = str(project_root / \"data\" / \"raw\")\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "async def scrape_telegram_channels():\n",
        "    \"\"\"\n",
        "    Main function to scrape data from Telegram channels.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Initialize the TelegramScraper\n",
        "        scraper = TelegramScraper(API_ID, API_HASH, PHONE)\n",
        "        \n",
        "        # Connect to Telegram API\n",
        "        await scraper.connect()\n",
        "        \n",
        "        # Scrape messages from multiple channels\n",
        "        await scraper.scrape_multiple_channels(\n",
        "            CHANNELS,\n",
        "            limit_per_channel=200,  # Adjust as needed\n",
        "            output_dir=OUTPUT_DIR,\n",
        "            output_format=\"json\"\n",
        "        )\n",
        "        \n",
        "        # Disconnect from Telegram API\n",
        "        await scraper.disconnect()\n",
        "        \n",
        "        print(f\"Successfully scraped data from {len(CHANNELS)} channels\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Error scraping Telegram channels: {e}\")\n",
        "\n",
        "# Run the scraping function\n",
        "# Note: This will prompt for authentication code when first connecting\n",
        "# asyncio.run(scrape_telegram_channels())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to load and display the scraped data\n",
        "def load_and_display_data(file_path=None):\n",
        "    \"\"\"\n",
        "    Load and display the scraped data.\n",
        "    \n",
        "    Args:\n",
        "        file_path: Path to the JSON file with scraped data\n",
        "    \"\"\"\n",
        "    if file_path is None:\n",
        "        # Find the most recent file\n",
        "        json_files = list(Path(OUTPUT_DIR).glob(\"all_messages_*.json\"))\n",
        "        if not json_files:\n",
        "            print(\"No data files found\")\n",
        "            return None\n",
        "        \n",
        "        # Use the most recent file\n",
        "        file_path = sorted(json_files)[-1]\n",
        "    \n",
        "    # Load the data\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        data = json.load(f)\n",
        "    \n",
        "    # Convert to DataFrame for easier analysis\n",
        "    df = pd.DataFrame(data)\n",
        "    \n",
        "    # Display basic statistics\n",
        "    print(f\"Loaded {len(df)} messages from {file_path}\")\n",
        "    print(f\"Channels: {df['channel'].nunique()}\")\n",
        "    print(f\"Date range: {df['date'].min()} to {df['date'].max()}\")\n",
        "    print(f\"Messages with media: {df['has_media'].sum()}\")\n",
        "    \n",
        "    # Display sample messages\n",
        "    print(\"\\nSample messages:\")\n",
        "    for i, row in df.sample(min(3, len(df))).iterrows():\n",
        "        print(f\"\\n--- Message from {row['channel']} ---\")\n",
        "        print(row['text'][:200] + \"...\" if len(row['text']) > 200 else row['text'])\n",
        "    \n",
        "    return df\n",
        "\n",
        "# Uncomment to load and display data after scraping\n",
        "# df = load_and_display_data()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze message statistics\n",
        "def analyze_message_statistics(df):\n",
        "    \"\"\"\n",
        "    Analyze message statistics from the scraped data.\n",
        "    \n",
        "    Args:\n",
        "        df: DataFrame with scraped messages\n",
        "    \"\"\"\n",
        "    if df is None or len(df) == 0:\n",
        "        print(\"No data to analyze\")\n",
        "        return\n",
        "    \n",
        "    # Convert date to datetime\n",
        "    df['date'] = pd.to_datetime(df['date'])\n",
        "    \n",
        "    # Messages per channel\n",
        "    channel_counts = df['channel'].value_counts()\n",
        "    print(\"Messages per channel:\")\n",
        "    print(channel_counts)\n",
        "    \n",
        "    # Messages per day\n",
        "    df['day'] = df['date'].dt.date\n",
        "    messages_per_day = df.groupby('day').size()\n",
        "    print(\"\\nMessages per day:\")\n",
        "    print(messages_per_day)\n",
        "    \n",
        "    # Average message length\n",
        "    df['text_length'] = df['text'].str.len()\n",
        "    avg_length = df['text_length'].mean()\n",
        "    print(f\"\\nAverage message length: {avg_length:.2f} characters\")\n",
        "    \n",
        "    # Messages with media\n",
        "    media_counts = df['media_type'].value_counts()\n",
        "    print(\"\\nMedia types:\")\n",
        "    print(media_counts)\n",
        "    \n",
        "    # Top 10 most viewed messages\n",
        "    if 'views' in df.columns:\n",
        "        top_views = df.sort_values('views', ascending=False).head(10)[['channel', 'views', 'text']]\n",
        "        print(\"\\nTop 10 most viewed messages:\")\n",
        "        for i, row in top_views.iterrows():\n",
        "            print(f\"\\n--- {row['channel']} ({row['views']} views) ---\")\n",
        "            print(row['text'][:100] + \"...\" if len(row['text']) > 100 else row['text'])\n",
        "\n",
        "# Uncomment to analyze message statistics after loading data\n",
        "# analyze_message_statistics(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the data for the next step in the pipeline\n",
        "def save_for_preprocessing(df, output_file=None):\n",
        "    \"\"\"\n",
        "    Save the data for the preprocessing step.\n",
        "    \n",
        "    Args:\n",
        "        df: DataFrame with scraped messages\n",
        "        output_file: Path to save the data\n",
        "    \"\"\"\n",
        "    if df is None or len(df) == 0:\n",
        "        print(\"No data to save\")\n",
        "        return\n",
        "    \n",
        "    if output_file is None:\n",
        "        # Create a timestamped filename\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        output_file = str(project_root / \"data\" / \"raw\" / f\"telegram_data_{timestamp}.csv\")\n",
        "    \n",
        "    # Save to CSV\n",
        "    df.to_csv(output_file, index=False, encoding=\"utf-8\")\n",
        "    print(f\"Data saved to {output_file}\")\n",
        "\n",
        "# Uncomment to save data for preprocessing\n",
        "# save_for_preprocessing(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Summary and Next Steps\n",
        "\n",
        "In this notebook, we have:\n",
        "\n",
        "1. Set up a Telegram API client to connect to Ethiopian e-commerce channels\n",
        "2. Created a function to scrape messages from these channels\n",
        "3. Implemented functions to analyze the collected data\n",
        "4. Prepared the data for the next step in our pipeline\n",
        "\n",
        "To use this notebook:\n",
        "\n",
        "1. Replace the API credentials with your own\n",
        "2. Add the Telegram channels you want to scrape to the CHANNELS list\n",
        "3. Uncomment and run the scrape_telegram_channels() function\n",
        "4. Load and analyze the scraped data\n",
        "5. Save the data for preprocessing\n",
        "\n",
        "In the next notebook, we will preprocess this data to prepare it for NER labeling.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
